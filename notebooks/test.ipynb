{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from lt_lib.core.matching import POLARS_AP_DF_SCHEMA\n",
    "from lt_lib.core.train import append_nested_dict_with_0\n",
    "\n",
    "from lt_lib.data.datasets import POLARS_GTS_SCHEMA\n",
    "import lt_lib.data.preprocessing as preprocessing\n",
    "\n",
    "from lt_lib.entrypoints.run import run, RunCliArgs\n",
    "from lt_lib.entrypoints.optimization import optimization, OptimizationCliArgs\n",
    "\n",
    "from lt_lib.orchestration.task_orchestrator import TaskOrchestrator\n",
    "\n",
    "from lt_lib.schemas.config_files_schemas import RunConfig, ModelConfig\n",
    "\n",
    "from lt_lib.utils.load_and_save import load_pytorch_checkpoint, load_json_as_dict\n",
    "from lt_lib.utils.dict_utils import flatten_dict\n",
    "from lt_lib.utils.regex_matcher import get_elements_with_regex\n",
    "from lt_lib.utils.update_outdated_objects import update_checkpoint_metrics_dict\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t = 4\n",
    "min_t = 1\n",
    "rf = 2\n",
    "s = 0\n",
    "\n",
    "MAX_RUNGS = int(np.log(max_t / min_t) / np.log(rf) - s + 1)\n",
    "\n",
    "[(min_t * rf ** (k + s), {}) for k in reversed(range(MAX_RUNGS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile([0.5, 0.7, 0.8, 0.55, 0.6, 0.57, 0.4], (1 - 1 / rf) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = load_pytorch_checkpoint(Path(\"/path/to/retinanet-E7.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"metrics\"][\"val\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_checkpoint_metrics_dict(Path(\"/path/to/retinanet-E7.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pl.from_dict({\"id\": [], \"img_name\":[], \"confidence\": [], \"label\": [], \"iou\": [], \"match\": [], \"correct_match\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pl.DataFrame(schema=POLARS_AP_DF_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "import torch\n",
    "from lt_lib.core.matching import boxes_iou\n",
    "from scipy.optimize import linear_sum_assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts_path = Path(\"/content/datasets/dataset_v1/val/annotations/gts.csv\")\n",
    "\n",
    "# Load gts and predictions csv files\n",
    "predictions = pl.read_csv(\"/path/to/predictions.csv\")\n",
    "gts = pl.read_csv(gts_path).cast(POLARS_GTS_SCHEMA, strict=True)\n",
    "\n",
    "label_to_label_name_dict = load_json_as_dict(Path(gts_path).parent / \"label_to_label_name.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pl.DataFrame()\n",
    "test_df = test_df.with_columns(label=np.array([1,2,3]))\n",
    "test_df = test_df.with_columns(img_name=pl.lit(\"img_test.jpg\"))\n",
    "test_df = test_df.with_columns(confidence=pl.lit(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.with_columns(confidence=pl.max_horizontal(pl.col(f\"^.*confidence.*$\")))\n",
    "predictions = predictions.filter(pl.col(\"confidence\") > 0.3)\n",
    "predictions.drop_in_place(\"id\")\n",
    "predictions = predictions.with_row_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image names list\n",
    "img_name_list = gts[\"img_name\"].unique().to_list()\n",
    "\n",
    "AP_df = predictions.select([\"id\", \"img_name\", \"probable_label\", \"confidence\"])\n",
    "AP_df = AP_df.rename({\"probable_label\": \"label\"})\n",
    "AP_df = AP_df.with_columns(iou=pl.lit(0.0, dtype=pl.Float32))\n",
    "AP_df = AP_df.with_columns(matched=pl.lit(0))\n",
    "\n",
    "# Processes images 1 by 1\n",
    "for img_name in tqdm(img_name_list):\n",
    "\n",
    "    # Filter image gts and predictions\n",
    "    img_gts = gts.filter(pl.col(\"img_name\") == img_name)\n",
    "    img_predictions = predictions.filter(pl.col(\"img_name\") == img_name)\n",
    "\n",
    "    # Get image gts and predictions bboxes\n",
    "    img_gts_bboxes = img_gts[[\"bbox_xmin\", \"bbox_ymin\", \"bbox_xmax\", \"bbox_ymax\"]].to_numpy()\n",
    "    img_gts_labels = img_gts[\"label\"].to_numpy()\n",
    "    img_predictions_bboxes = img_predictions[[\"bbox_xmin\", \"bbox_ymin\", \"bbox_xmax\", \"bbox_ymax\"]].to_numpy()\n",
    "    img_predictions_id = img_predictions[\"id\"].to_numpy()\n",
    "    img_predictions_probable_labels = img_predictions[\"probable_label\"].to_numpy()\n",
    "\n",
    "    # Computes the iou matrix between detecions and gts\n",
    "    iou_matrix = boxes_iou(img_predictions_bboxes, img_gts_bboxes)\n",
    "\n",
    "    # Hugarian algorithm to match predictions with gts. It returns predictions_indexes and column_indexes matched\n",
    "    predictions_idx, gts_idx = linear_sum_assignment(1 - iou_matrix)\n",
    "\n",
    "    AP_df = AP_df.with_columns(\n",
    "        iou=AP_df[\"iou\"].scatter(img_predictions_id[predictions_idx], iou_matrix[predictions_idx, gts_idx])\n",
    "    )\n",
    "\n",
    "    mask_correct_matched = img_gts_labels[gts_idx] == img_predictions_probable_labels[predictions_idx]\n",
    "    AP_df = AP_df.with_columns(\n",
    "        matched=AP_df[\"matched\"].scatter(img_predictions_id[predictions_idx], mask_correct_matched.astype(int))\n",
    "    )\n",
    "    \n",
    "    mask = np.ones(img_gts_labels.shape, dtype=bool)\n",
    "    mask[gts_idx] = False\n",
    "    unmatched_gts_labels = img_gts_labels[mask]\n",
    "    if len(unmatched_gts_labels) != 0:\n",
    "        unmatched_gts = pl.DataFrame({\"label\":unmatched_gts_labels})\n",
    "        unmatched_gts = unmatched_gts.insert_column(0, pl.Series(\"img_name\", [img_name] * len(unmatched_gts_labels)))\n",
    "        unmatched_gts = unmatched_gts.with_columns(\n",
    "            confidence=pl.lit(0.0, dtype=pl.Float32),\n",
    "            iou=pl.lit(0.0, dtype=pl.Float32),\n",
    "            matched=pl.lit(0),\n",
    "        )\n",
    "        unmatched_gts = unmatched_gts.with_row_index(\"id\", offset=len(AP_df))\n",
    "\n",
    "        AP_df = pl.concat([AP_df, unmatched_gts], how=\"vertical_relaxed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_df_filtered = AP_df.filter(pl.col(\"label\").is_in([1,2,3]))\n",
    "AP_df_filtered.drop_in_place(\"id\")\n",
    "AP_df_filtered = AP_df_filtered.with_row_index(\"id\")\n",
    "\n",
    "AP_per_thresh = []\n",
    "for iou_thresh in np.linspace(0.5, 0.95, 10):\n",
    "    too_low_iou_ids = AP_df_filtered.filter(pl.col(\"matched\") == 1, pl.col(\"iou\").is_between(0, iou_thresh, closed=\"right\"))[\"id\"]\n",
    "    AP_df_filtered = AP_df_filtered.with_columns(\n",
    "        matched=AP_df_filtered[\"matched\"].scatter(too_low_iou_ids, 0)\n",
    "    )\n",
    "    fn_df = AP_df_filtered.filter(pl.col(\"id\").is_in(too_low_iou_ids.to_list()))\n",
    "    fn_df = fn_df.with_columns(confidence=pl.lit(0.0), iou=pl.lit(0.0))\n",
    "    fn_df.drop_in_place(\"id\")\n",
    "    fn_df = fn_df.with_row_count(\"id\", offset=len(AP_df_filtered))\n",
    "    AP_df_filtered = pl.concat([AP_df_filtered, fn_df], how=\"vertical_relaxed\")\n",
    "\n",
    "    AP_per_label = []\n",
    "    for label in  AP_df_filtered[\"label\"].unique():\n",
    "        AP_df_filtered_per_label = AP_df_filtered.filter(pl.col(\"label\") == label)\n",
    "        AP_per_label.append(average_precision_score(AP_df_filtered_per_label[\"matched\"], AP_df_filtered_per_label[\"confidence\"]))\n",
    "    AP_per_thresh.append(np.mean(AP_per_label))\n",
    "\n",
    "np.mean(AP_per_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT_DIR_PATH = Path(\"/content/datasets/dataset_v0/train\")\n",
    "\n",
    "# global_gdf, minimal_gts = preprocessing.get_all_annotations_from_rareplanes_geojsons(\n",
    "#     root_dir_path = ROOT_DIR_PATH,\n",
    "#     tiled_version = True,\n",
    "#     imgs_extension=\".png\",\n",
    "#     save_to_file = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gts_csv_path = ROOT_DIR_PATH / \"annotations/gts.csv\")\n",
    "# gts = pl.read_csv(gts_csv_path)\n",
    "# np.unique(gts[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gts = gts.with_columns(pl.col(\"label\").replace({2:1, 4: 2, 6: 3}))\n",
    "# gts.cast(POLARS_GTS_SCHEMA, strict=True).write_csv(gts_csv_path)\n",
    "\n",
    "# minimal_gts_json = {}\n",
    "# for img_name in np.unique(gts[\"img_name\"].to_list()):\n",
    "#     sub_img_df = gts.filter(pl.col(\"img_name\") == img_name)\n",
    "#     minimal_gts_json[img_name] = {\n",
    "#         \"ids\": sub_img_df[\"id\"].to_list(),\n",
    "#         \"bboxes\": sub_img_df[[\"bbox_xmin\", \"bbox_ymin\", \"bbox_xmax\", \"bbox_ymax\"]].to_numpy().tolist(),\n",
    "#         \"labels\": sub_img_df[\"label\"].to_list(),\n",
    "#     }\n",
    "# with open(Path(\"/\".join(gts_csv_path.parts)[1:-3] + 'json'), \"w\") as file:\n",
    "#     json.dump(minimal_gts_json, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_orchestrator = TaskOrchestrator(\n",
    "    inputs_dir=Path(\"/content/datasets/dataset_test\"),\n",
    "    outputs_dir=Path(\"/content/outputs/outputs_test\"),\n",
    "    config_path=\"predict_config_test.yaml\",\n",
    "    model_config_path=\"model_config_test.yaml\",\n",
    "    resume=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = RunCliArgs(\n",
    "    inputs_directory=\"/content/datasets/dataset_test\",\n",
    "    outputs_directory=\"/content/outputs/outputs_test\",\n",
    "    model_config_path=\"model_config_test.yaml\",\n",
    "    config_path=\"full_config_test.yaml\",\n",
    "    resume=True,\n",
    ")\n",
    "\n",
    "run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = OptimizationCliArgs(\n",
    "    inputs_directory=\"/content/datasets/dataset_test\",\n",
    "    outputs_directory=\"/content/outputs/outputs_test\",\n",
    "    # model_config_path=\"../configs/model_config_test.yaml\",\n",
    "    config_path=\"/content/master-thesis-draft/configs/thresh_eval_config.yaml\",\n",
    "    optimization_config_path=\"/content/master-thesis-draft/configs/optimization_config.py\",\n",
    "    restore_dir_path=\"\",\n",
    ")\n",
    "\n",
    "optimization(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xview exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(Path(\"/path/to/xView_train.geojson\"))\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(gdf.drop(columns=[\"geometry\", \"grid_file\", \"feature_id\", \"point_geom\", \"index_right\", \"ingest_time\", \"cat_id\", \"edited_by\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"type_id\") == 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data wingspan exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = pl.read_csv(\"/content/datasets/synthetic_data_sampled_10percent_seed42/annotations/gts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_resolution = 0.31\n",
    "print(15/imgs_resolution)\n",
    "print(36/imgs_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts.filter(pl.col(\"wingspan\").is_between(112.5, 120))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
